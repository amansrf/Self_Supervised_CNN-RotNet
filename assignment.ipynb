{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roar/anaconda3/envs/RotNet_jax/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-07 20:44:41.252877: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib\n",
      "2022-12-07 20:44:41.252933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib\n",
      "2022-12-07 20:44:41.252938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "\n",
    "from dataloader import load_data\n",
    "from RotNet import rotnet_constructor\n",
    "from PredNet import prednet_constructor\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax.linen as nn\n",
    "from flax import traverse_util\n",
    "from flax.core.frozen_dict import freeze\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cifar10 image shape\n",
    "CIFAR10_INPUT_SHAPE = (1, 32, 32, 3)\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    batch_stats: Any\n",
    "\n",
    "def cross_entropy_loss_(logits, labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Define loss: https://flax.readthedocs.io/en/latest/getting_started.html#define-loss\n",
    "    \"\"\"\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=num_classes)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
    "cross_entropy_loss = jax.jit(cross_entropy_loss_, static_argnums=2)\n",
    "\n",
    "def compute_metrics_(logits, labels, num_classes):\n",
    "    \"\"\"\n",
    "    Metric computation: https://flax.readthedocs.io/en/latest/getting_started.html#metric-computation\n",
    "    \"\"\"\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels, num_classes=num_classes)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\"loss\": loss, \"accuracy\": accuracy}\n",
    "    return metrics\n",
    "compute_metrics = jax.jit(compute_metrics_, static_argnums=2)\n",
    "\n",
    "def create_train_state(rng, model, learning_rate, momentum):\n",
    "    \"\"\"\n",
    "    Create train state: https://flax.readthedocs.io/en/latest/getting_started.html#create-train-state\n",
    "    \"\"\"\n",
    "    variables = model.init(rng, jnp.ones(CIFAR10_INPUT_SHAPE, dtype=model.dtype), train=False)\n",
    "    # TODO: get params and batch_state from varaibles\n",
    "    # hint: Check the documentation of model.init, and find out how to use it\n",
    "    params, batch_stats = ... , ...\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    state = TrainState.create(apply_fn=model.apply, params=params, tx=tx, batch_stats=batch_stats)\n",
    "    return state, variables\n",
    "\n",
    "def train_batch_(state, images, labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Training step: https://flax.readthedocs.io/en/latest/getting_started.html#training-step\n",
    "    \"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits, updates = state.apply_fn(\n",
    "            {\"params\": params, \"batch_stats\": state.batch_stats}, images, mutable=[\"batch_stats\"], train=True\n",
    "        )\n",
    "        loss = cross_entropy_loss(logits=logits, labels=labels, num_classes=num_classes)\n",
    "        return loss, (logits, updates)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (logits, updates)), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    state = state.replace(batch_stats=updates[\"batch_stats\"])\n",
    "    metrics = compute_metrics(logits=logits, labels=labels, num_classes=num_classes)\n",
    "    return state, metrics\n",
    "train_batch = jax.jit(train_batch_, static_argnums=3)\n",
    "\n",
    "def train_epoch(state, dataloader, num_classes=10):\n",
    "    \"\"\"\n",
    "    Train function: https://flax.readthedocs.io/en/latest/getting_started.html#train-function\n",
    "    \"\"\"\n",
    "    batch_metrics = []\n",
    "    for images, labels in dataloader:\n",
    "        state, metrics = train_batch(state, images, labels, num_classes=num_classes)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np]) for k in batch_metrics_np[0]\n",
    "    }\n",
    "    return state, epoch_metrics_np\n",
    "\n",
    "def eval_batch_(state, images, labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Evaluation step: https://flax.readthedocs.io/en/latest/getting_started.html#evaluation-step\n",
    "    \"\"\"\n",
    "    logits = state.apply_fn(\n",
    "        {\"params\": state.params, \"batch_stats\": state.batch_stats}, images, mutable=False, train=False\n",
    "    )\n",
    "    return compute_metrics(logits=logits, labels=labels, num_classes=num_classes)\n",
    "eval_batch = jax.jit(eval_batch_, static_argnums=3)\n",
    "\n",
    "def eval_model(state, dataloader, num_classes=10):\n",
    "    \"\"\"\n",
    "    Eval function: https://flax.readthedocs.io/en/latest/getting_started.html#eval-function\n",
    "    \"\"\"\n",
    "    batch_metrics = []\n",
    "    for images, labels in dataloader:\n",
    "        metrics = eval_batch(state, images, labels, num_classes=num_classes)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    validation_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np]) for k in batch_metrics_np[0]\n",
    "    }\n",
    "    return validation_metrics_np[\"loss\"], validation_metrics_np[\"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    \n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "    \n",
    "    # Define What RotNet architecture to use. \n",
    "    rotnet_arch : str = \"rotnet3_feat3\" #@param[\"rotnet3_feat3\"] \n",
    "    # Define What PredNet architecture to use. \n",
    "    prednet_arch: str = \"prednet3\" #@param[\"rotnet3_feat3\"]\n",
    "    # Define Directory to Save RotNet Checkpoints\"\n",
    "    rotnet_ckpt_dir: str = \"./ckpts/ro state = TrainState.create(apply_fn=model.apply, params=params, tx=tx, batch_stats=batch_stats)tnet\" #@param[\"rotnet3_feat3\"]\n",
    "    # Define Directory to Save PredNet Checkpoints\n",
    "    prednet_ckpt_dir: str = \"./ckpts/prednet\" #@param[\"rotnet3_feat3\"]\n",
    "    # Continue to Train RotNet from rotnet_ckpt_epoch\n",
    "    rotnet_ckpt_epoch: int = 0 #@param {type: \"integer\"}\n",
    "    # Continue to train PredNet from prednet_ckpt_epoch\n",
    "    prednet_ckpt_epoch: int = 0 #@param {type: \"integer\"}\n",
    "    # Train RotNet for rotnet_epochs in Total\n",
    "    rotnet_epochs: int = 10 #@param {type: \"integer\"}\n",
    "    # Train PredNet for prednet_epochs in Total\n",
    "    prednet_epochs: int = 10 #@param {type: \"integer\"}\n",
    "    # Disable Gradient Flow in RotNet if Set to True\n",
    "    no_grad: bool = True #@param {type: \"boolean\"}\n",
    "    # Batch Size Per Process\"\n",
    "    batch_size: int = 128 #@param {type: \"integer\"}\n",
    "    # Number of Data Loading Workers\n",
    "    workers: int = 4 #@param {type: \"integer\"}\n",
    "    # Learning Rate of the Optimizer\n",
    "    lr: float = 1e-3 #@param {type: \"float\"}\n",
    "    # Momentum of the Optimizer\n",
    "    momentum: float = 0.9 #@param {type: \"float\"}\n",
    "    # Print Model and Params Info\n",
    "    verbose: bool = False #@param {type: \"boolean\"}\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Key Generated\n",
      "Network Defined\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data Loaded\n",
      "Train State Created\n",
      "RotNet Checkpoint Directory Created\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Generate JAX Random Number Key ---------------------- #\n",
    "rng = jax.random.PRNGKey(0)\n",
    "print(\"Random Key Generated\")\n",
    "\n",
    "# -------------------------- Create the RotNet Model ------------------------- #\n",
    "# Define network: https://flax.readthedocs.io/en/latest/getting_started.html#define-network\n",
    "# TODO: In order to construct a RotNet, you need to fill in all the TODOs in RotNet.py. Check the above link for hints.\n",
    "rotnet_model = rotnet_constructor(args.rotnet_arch)\n",
    "print(\"Network Defined\")\n",
    "if args.verbose:\n",
    "    print(nn.tabulate(rotnet_model, rng)(jnp.ones(CIFAR10_INPUT_SHAPE), False))\n",
    "\n",
    "# ------------------------- Load the CIFAR10 Dataset ------------------------- #\n",
    "# Loading data: https://flax.readthedocs.io/en/latest/getting_started.html#loading-data\n",
    "# NOTE: Choose batch_size and workers based on system specs.\n",
    "# NOTE: This dataloader requires pytorch to load the datset for convenience.\n",
    "# TODO: In order to create the dataset, you will need to implement rotate_image function in utils.py. Chech the above link for hints.\n",
    "loaders = load_data(batch_size=args.batch_size, workers=args.workers)\n",
    "train_loader, validation_loader, test_loader, rot_train_loader, rot_validation_loader, rot_test_loader = loaders\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "# --- Create the Train State Abstraction (see documentation in link below) --- #\n",
    "# Create train state: https://flax.readthedocs.io/en/latest/getting_started.html#create-train-state\n",
    "rotnet_state, rotnet_variables = create_train_state(rng, rotnet_model, args.lr, args.momentum)\n",
    "print(\"Train State Created\")\n",
    "\n",
    "# ----------------- Specify the Directory to Save Checkpoints ---------------- #\n",
    "rotnet_ckpt_dir = args.rotnet_ckpt_dir\n",
    "if not os.path.exists(rotnet_ckpt_dir):\n",
    "    os.makedirs(rotnet_ckpt_dir)\n",
    "    print(\"RotNet Checkpoint Directory Created\")\n",
    "else:\n",
    "    print(\"RotNet Checkpoint Directory Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a RotNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RotNet Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1,         loss: 1.1226,         accuracy:57.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:26<03:59, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.9133, validation accuracy:64.15%\n",
      "train epoch: 2,         loss: 0.8422,         accuracy:66.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:51<03:24, 25.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.8266, validation accuracy:67.87%\n",
      "train epoch: 3,         loss: 0.7403,         accuracy:71.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:16<02:56, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7856, validation accuracy:69.32%\n",
      "train epoch: 4,         loss: 0.6743,         accuracy:73.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:41<02:30, 25.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7866, validation accuracy:69.66%\n",
      "train epoch: 5,         loss: 0.6203,         accuracy:76.10%\n",
      "validation loss: 0.7553, validation accuracy:71.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:10<02:13, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "test_accuracy: 70.27%\n",
      "====================\n",
      "train epoch: 6,         loss: 0.5753,         accuracy:78.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:35<01:43, 25.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7674, validation accuracy:70.43%\n",
      "train epoch: 7,         loss: 0.5348,         accuracy:79.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:59<01:16, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7377, validation accuracy:71.85%\n",
      "train epoch: 8,         loss: 0.5017,         accuracy:81.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [03:24<00:50, 25.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.7988, validation accuracy:69.95%\n",
      "train epoch: 9,         loss: 0.4677,         accuracy:82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:49<00:25, 25.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.8497, validation accuracy:69.34%\n",
      "train epoch: 10,         loss: 0.4431,         accuracy:83.47%\n",
      "validation loss: 0.8121, validation accuracy:70.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:19<00:00, 25.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "test_accuracy: 70.45%\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load Existing Checkpoint of RotNet -------------------- #\n",
    "if args.rotnet_ckpt_epoch > 0:\n",
    "    # TODO: Load pre-trained model if required\n",
    "    # hint: Check out flax.training.checkpoints.restore_checkpoint function\n",
    "    rotnet_state = ...\n",
    "    print(\"RotNet Checkpoint Loaded\")\n",
    "\n",
    "# ----------------------------- Train the RotNet ----------------------------- #\n",
    "print(\"Starting RotNet Training Loop\")\n",
    "for epoch in tqdm(range(args.rotnet_ckpt_epoch + 1, args.rotnet_epochs + 1)):\n",
    "    # ------------------------------- Training Step ------------------------------ #\n",
    "    # Training step: https://flax.readthedocs.io/en/latest/getting_started.html#training-step\n",
    "    # TODO: Use train_epoch defined aboove to train a RotNet \n",
    "    rotnet_state, train_epoch_metrics = ...\n",
    "\n",
    "    # Print training metrics every epoch\n",
    "    print(\n",
    "        f\"train epoch: {epoch}, \\\n",
    "        loss: {train_epoch_metrics['loss']:.4f}, \\\n",
    "        accuracy:{train_epoch_metrics['accuracy']*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------ Evaluation Step ----------------------------- #\n",
    "    # Evaluation step: https://flax.readthedocs.io/en/latest/getting_started.html#evaluation-step\n",
    "    # TODO: Use eval_model defined aboove to get validation loss and accuracy\n",
    "    validation_loss, validation_accuracy = ...\n",
    "    \n",
    "    # Print validation metrics every epoch\n",
    "    print(f\"validation loss: {validation_loss:.4f}, validation accuracy:{validation_accuracy*100:.2f}%\")\n",
    "\n",
    "    # ---------------------------- Saving Checkpoints ---------------------------- #\n",
    "    # ---- https://flax.readthedocs.io/en/latest/guides/use_checkpointing.html --- #\n",
    "    checkpoints.save_checkpoint(\n",
    "        ckpt_dir=rotnet_ckpt_dir, target=rotnet_state, step=epoch, overwrite=True, keep=args.rotnet_epochs\n",
    "    )\n",
    "\n",
    "    # Print test metrics every nth epoch\n",
    "    if epoch % 5 == 0:\n",
    "        _, test_accuracy = eval_model(rotnet_state, rot_test_loader, num_classes=4)\n",
    "        print(\"====================\")\n",
    "        print(f\"test_accuracy: {test_accuracy*100:.2f}%\")\n",
    "        print(\"====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for training PredNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredNet Checkpoint Directory Created\n"
     ]
    }
   ],
   "source": [
    "# ---- https://flax.readthedocs.io/en/latest/guides/transfer_learning.html --- #\n",
    "# ----------------------------- Extract Backbone ----------------------------- #\n",
    "def extract_submodule(model):\n",
    "    feature_extractor = model.features.clone()\n",
    "    # TODO: extract variable from model\n",
    "    # hint: checkout https://flax.readthedocs.io/en/latest/guides/transfer_learning.html\n",
    "    variables = ...\n",
    "    return feature_extractor, variables\n",
    "\n",
    "backbone_model, backbone_model_variables = nn.apply(extract_submodule, rotnet_model)(rotnet_variables)\n",
    "\n",
    "# ------------------------- Create the Prednet Model ------------------------- #\n",
    "# TODO: Construct your PredNet\n",
    "# hint: Check out how the RotNet was defined above\n",
    "prednet_model = ...\n",
    "\n",
    "# ----------------------- Extract Variables and Params ----------------------- #\n",
    "prednet_variables   = prednet_model.init(rng, jnp.ones(CIFAR10_INPUT_SHAPE), train=False)\n",
    "prednet_params      = prednet_variables['params']\n",
    "prednet_batch_stats = prednet_variables['batch_stats']\n",
    "\n",
    "# --------------------- Transfer the Backbone Parameters --------------------- #\n",
    "prednet_params              = prednet_params.unfreeze()\n",
    "prednet_params['backbone']  = backbone_model_variables['params']\n",
    "prednet_params              = freeze(prednet_params)\n",
    "\n",
    "if not args.no_grad:\n",
    "    prednet_batch_stats              = prednet_batch_stats.unfreeze()\n",
    "    prednet_batch_stats['backbone']  = backbone_model_variables['batch_stats']\n",
    "    prednet_batch_stats              = freeze(prednet_batch_stats)\n",
    "\n",
    "# -------------------------- Define How to Backprop -------------------------- #\n",
    "if args.no_grad:\n",
    "    # TODO: Freeze layers with optax.multi_transform for the mode\n",
    "    ############### Your Code Starts Here ###################\n",
    "    # hint: Check out https://flax.readthedocs.io/en/latest/guides/transfer_learning.html\n",
    "    partition_optimizers = {'trainable': optax.sgd(args.lr, args.momentum), 'frozen': optax.set_to_zero()}\n",
    "    \n",
    "    \n",
    "    prednet_param_partitions = ...\n",
    "    \n",
    "\n",
    "    tx = optax.multi_transform(partition_optimizers, prednet_param_partitions)\n",
    "    \n",
    "    ############### Your Code Ends Here ###################\n",
    "\n",
    "    # ---------------- Visualize param_partitions to double check ---------------- #\n",
    "    if args.verbose:\n",
    "        flat = list(traverse_util.flatten_dict(prednet_param_partitions).items())\n",
    "        freeze(traverse_util.unflatten_dict(dict(flat[:2] + flat[-2:])))\n",
    "        \n",
    "else:\n",
    "    tx = optax.sgd(args.lr, args.momentum)\n",
    "    \n",
    "# ---------------------- Create Train State for PredNet ---------------------- #\n",
    "# TODO: Create Train State for PredNet\n",
    "# hint: We also did it for RotNet.\n",
    "prednet_state = ...\n",
    "\n",
    "# ----------------- Specify the Directory to Save Checkpoints ---------------- #\n",
    "prednet_ckpt_dir = args.prednet_ckpt_dir\n",
    "if not os.path.exists(prednet_ckpt_dir):\n",
    "    os.makedirs(prednet_ckpt_dir)\n",
    "    print(\"PredNet Checkpoint Directory Created\")\n",
    "else:\n",
    "    print(\"PredNet Checkpoint Directory Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a PredNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PredNet Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1,         loss: 1.8956,         accuracy:46.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:10<01:31, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.7487, validation accuracy:44.49%\n",
      "train epoch: 2,         loss: 0.7775,         accuracy:73.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:16<01:01,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.3920, validation accuracy:56.07%\n",
      "train epoch: 3,         loss: 0.3648,         accuracy:88.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:21<00:47,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.2737, validation accuracy:59.16%\n",
      "train epoch: 4,         loss: 0.1739,         accuracy:96.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:27<00:38,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.3250, validation accuracy:59.86%\n",
      "train epoch: 5,         loss: 0.0904,         accuracy:99.17%\n",
      "validation loss: 1.2508, validation accuracy:61.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:34<00:33,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "test_accuracy: 61.96%\n",
      "====================\n",
      "train epoch: 6,         loss: 0.0547,         accuracy:99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:40<00:25,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.2069, validation accuracy:62.70%\n",
      "train epoch: 7,         loss: 0.0382,         accuracy:99.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:46<00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.2222, validation accuracy:63.71%\n",
      "train epoch: 8,         loss: 0.0287,         accuracy:99.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:52<00:12,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.2276, validation accuracy:64.18%\n",
      "train epoch: 9,         loss: 0.0238,         accuracy:100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:58<00:06,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 1.2417, validation accuracy:64.06%\n",
      "train epoch: 10,         loss: 0.0202,         accuracy:100.00%\n",
      "validation loss: 1.2510, validation accuracy:64.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "test_accuracy: 64.38%\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load Existing Checkpoint of PredNet ------------------- #\n",
    "if args.prednet_ckpt_epoch > 0:\n",
    "    prednet_state = checkpoints.restore_checkpoint(\n",
    "        ckpt_dir=prednet_ckpt_dir, target=prednet_state, step=args.prednet_ckpt_epoch\n",
    "    )\n",
    "    print(\"PredNet Checkpoint Loaded\")\n",
    "\n",
    "# ----------------------------- Train the PredNet ---------------------------- #\n",
    "print(\"Starting PredNet Training Loop\")\n",
    "for epoch in tqdm(range(args.prednet_ckpt_epoch + 1, args.prednet_epochs + 1)):\n",
    "    # ------------------------------- Training Step ------------------------------ #\n",
    "    # Training step: https://flax.readthedocs.io/en/latest/getting_started.html#training-step\n",
    "    # TODO: Use train_epoch defined aboove to train a RotNet \n",
    "    prednet_state, train_epoch_metrics = ...\n",
    "\n",
    "    # Print training metrics every epoch\n",
    "    print(\n",
    "        f\"train epoch: {epoch}, \\\n",
    "        loss: {train_epoch_metrics['loss']:.4f}, \\\n",
    "        accuracy:{train_epoch_metrics['accuracy']*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------ Evaluation Step ----------------------------- #\n",
    "    # Evaluation step: https://flax.readthedocs.io/en/latest/getting_started.html#evaluation-step\n",
    "    # TODO: Use eval_model defined aboove to get validation loss and accuracy\n",
    "    validation_loss, validation_accuracy = ...\n",
    "    \n",
    "    # Print validation metrics every epoch\n",
    "    print(f\"validation loss: {validation_loss:.4f}, validation accuracy:{validation_accuracy*100:.2f}%\")\n",
    "\n",
    "    # ---------------------------- Saving Checkpoints ---------------------------- #\n",
    "    # ---- https://flax.readthedocs.io/en/latest/guides/use_checkpointing.html --- #\n",
    "    checkpoints.save_checkpoint(\n",
    "        ckpt_dir=prednet_ckpt_dir, target=prednet_state, step=epoch, overwrite=True, keep=args.prednet_epochs\n",
    "    )\n",
    "\n",
    "    # Print test metrics every nth epoch\n",
    "    if epoch % 5 == 0:\n",
    "        _, test_accuracy = eval_model(prednet_state, test_loader, num_classes=10)\n",
    "        print(\"====================\")\n",
    "        print(f\"test_accuracy: {test_accuracy*100:.2f}%\")\n",
    "        print(\"====================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('RotNet_jax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36223b7e67465e2419268c36c29acc23eab32b6397e879adf42dead3fc750add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
